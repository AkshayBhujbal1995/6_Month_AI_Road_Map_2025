{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0993f2a2-5a76-4a8f-9f09-c62f7d8709fe",
   "metadata": {},
   "source": [
    "# NLU – Text Preprocessing Quick Reference\n",
    "\n",
    "**What is NLP?**\n",
    "\n",
    "**Natural Language Processing (NLP)** is a field of AI that enables computers to understand, interpret, and generate human language.\n",
    "\n",
    "**Two main parts of NLP:**\n",
    "\n",
    "1. **NLU – Natural Language Understanding**\n",
    "   - Focuses on understanding meaning from text/speech.\n",
    "   - Example tasks: sentiment analysis, entity recognition, question answering.\n",
    "2. **NLG – Natural Language Generation**\n",
    "   - Focuses on producing human-like language.\n",
    "   - Example tasks: chatbots replying to users, AI writing articles.\n",
    "\n",
    "This notebook covers **NLU** – the first part of NLP.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3748a47-4dd2-40a0-8c87-c13ac0073cff",
   "metadata": {},
   "source": [
    "# Tokenization\n",
    "## Word Tokenization\n",
    "\n",
    "- Splits text into individual words and punctuation.\n",
    "- **When to use:** Any NLP pipeline as the first step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4843552f-fcd3-4e9c-8fb8-786a9566f1ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural',\n",
       " 'Language',\n",
       " 'Understanding',\n",
       " 'helps',\n",
       " 'AI',\n",
       " 'systems',\n",
       " 'interpret',\n",
       " 'human',\n",
       " 'language',\n",
       " '.']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "text = \"Natural Language Understanding helps AI systems interpret human language.\"\n",
    "word_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bd89eb-b734-4e4d-8fdd-dc73d9d74c07",
   "metadata": {},
   "source": [
    "## Sentence Tokenization\n",
    "- Splits text into sentences.\n",
    "- **When to use:** Summarization, dialogue systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "189f76dd-517e-4f49-a719-790e456b7fc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural Language Understanding helps AI systems interpret human language.']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8232e48-8756-49ae-a12d-5a3c9eb5fdd7",
   "metadata": {},
   "source": [
    "## Paragraph Tokenization\n",
    "- Splits text into paragraphs by blank lines.\n",
    "- **When to use:** Document-level analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c815856b-f31f-4dca-96ce-30dd7213049f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural Language Understanding helps AI systems interpret human language.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import blankline_tokenize\n",
    "blankline_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764c0778-b59c-48bf-bad6-1e42fab2601a",
   "metadata": {},
   "source": [
    "## Whitespace Tokenizer\n",
    "- Splits by spaces/tabs, punctuation remains.\n",
    "- **When to use:** Emails, URLs, structured text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e2f653d-583d-4d66-afc8-b81bcbb90289",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural',\n",
       " 'Language',\n",
       " 'Understanding',\n",
       " 'helps',\n",
       " 'AI',\n",
       " 'systems',\n",
       " 'interpret',\n",
       " 'human',\n",
       " 'language.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "WhitespaceTokenizer().tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532dbf94-1a97-4b69-8c94-b946918625b9",
   "metadata": {},
   "source": [
    "## WordPunct Tokenizer\n",
    "- Splits words and punctuation separately.\n",
    "- **When to use:** Emoticons, hashtags, code parsing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61f5a430-9898-4ecb-89bb-44cab766b895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural',\n",
       " 'Language',\n",
       " 'Understanding',\n",
       " 'helps',\n",
       " 'AI',\n",
       " 'systems',\n",
       " 'interpret',\n",
       " 'human',\n",
       " 'language',\n",
       " '.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize\n",
    "wordpunct_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6138da-e85f-4b36-9ff8-13d57d0263e0",
   "metadata": {},
   "source": [
    "# N-grams\n",
    "- Groups words into sequences of N.\n",
    "- **When to use:** Text prediction, context analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e74259ac-05d1-4794-9434-5bdc50bde8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "tokens = nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692eb7ad-6e99-4712-b889-e621099efedd",
   "metadata": {},
   "source": [
    "## Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c689553a-cc7d-4acc-840f-cea30aadf64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Natural', 'Language'), ('Language', 'Understanding'), ('Understanding', 'helps'), ('helps', 'AI'), ('AI', 'systems'), ('systems', 'interpret'), ('interpret', 'human'), ('human', 'language'), ('language', '.')]\n"
     ]
    }
   ],
   "source": [
    "print(list(nltk.bigrams(tokens)))   # Bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b083a89-e8f9-40c3-a7de-ba75b7401490",
   "metadata": {},
   "source": [
    "## Trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "346467f2-0eff-4130-879b-2e6850ea9370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Natural', 'Language', 'Understanding'), ('Language', 'Understanding', 'helps'), ('Understanding', 'helps', 'AI'), ('helps', 'AI', 'systems'), ('AI', 'systems', 'interpret'), ('systems', 'interpret', 'human'), ('interpret', 'human', 'language'), ('human', 'language', '.')]\n"
     ]
    }
   ],
   "source": [
    "print(list(nltk.trigrams(tokens)))  # Trigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136a7efa-85a6-4fb0-be16-84aaea333e47",
   "metadata": {},
   "source": [
    "## 4-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94f94c3c-e068-464a-8150-616149d85860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Natural', 'Language', 'Understanding', 'helps'), ('Language', 'Understanding', 'helps', 'AI'), ('Understanding', 'helps', 'AI', 'systems'), ('helps', 'AI', 'systems', 'interpret'), ('AI', 'systems', 'interpret', 'human'), ('systems', 'interpret', 'human', 'language'), ('interpret', 'human', 'language', '.')]\n"
     ]
    }
   ],
   "source": [
    "print(list(nltk.ngrams(tokens, 4))) # 4-grams"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620f8100-1395-484b-bdcc-063f6fdfc5b1",
   "metadata": {},
   "source": [
    "# Stemming\n",
    "- Reduces words to root form (may not be real words).\n",
    "- **When to use:** Fast processing, search engines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "661d0b0d-3dcb-4ad1-83de-a485e0ea29ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, LancasterStemmer, SnowballStemmer\n",
    "\n",
    "words = ['running', 'runs', 'easily', 'fairly']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4eaa23-1fea-463c-a644-117d91171fc4",
   "metadata": {},
   "source": [
    "## PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34db5c8b-112a-4c36-8242-ad5fc0bc7070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['run', 'run', 'easili', 'fairli']\n"
     ]
    }
   ],
   "source": [
    "print([PorterStemmer().stem(w) for w in words])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df8dd2f-eb56-46c7-b45f-1a094218101d",
   "metadata": {},
   "source": [
    "## LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d19d925f-a076-454d-9bd6-42c6c6ff94a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['run', 'run', 'easy', 'fair']\n"
     ]
    }
   ],
   "source": [
    "print([LancasterStemmer().stem(w) for w in words])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2614db83-4b64-41ee-b651-b29246bc48a7",
   "metadata": {},
   "source": [
    "## SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f030a270-3da3-46a1-9fc0-9c5bcb2f0f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['run', 'run', 'easili', 'fair']\n"
     ]
    }
   ],
   "source": [
    "print([SnowballStemmer('english').stem(w) for w in words])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eea099b-efc4-4647-bc5f-efaef76d1001",
   "metadata": {},
   "source": [
    "# Lemmatization\n",
    "- Reduces words to their dictionary form, considering meaning.\n",
    "- **When to use:** Accurate text analysis (sentiment, topic modeling)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec27a606-ed0f-466e-9f98-153671a9b5ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "wnl = WordNetLemmatizer()\n",
    "wnl.lemmatize('running', pos='v')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5e859f-f97f-43af-8ea5-057f7bdfc131",
   "metadata": {},
   "source": [
    "# Stopwords Removal\n",
    "- Removes common words that add little meaning.\n",
    "- **When to use:** Text classification, clustering (if stopwords are not important)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff161be3-0229-4b97-b54d-b52a1a93ef43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an']\n",
      "Stopwords count: 198\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "print(stopwords.words('english')[:10])\n",
    "print(\"Stopwords count:\", len(stopwords.words('english')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1a6786-478d-4668-ab18-8bdde863d305",
   "metadata": {},
   "source": [
    "# POS Tagging\n",
    "- Assigns grammatical roles (noun, verb, adjective) to tokens.\n",
    "- **When to use:** Syntax analysis, NER, grammar correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "434d9366-8fa6-49b1-98cb-39b30e728ac7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Natural', 'JJ'),\n",
       " ('Language', 'NNP'),\n",
       " ('Understanding', 'NNP'),\n",
       " ('helps', 'VBZ'),\n",
       " ('AI', 'NNP'),\n",
       " ('systems', 'NNS'),\n",
       " ('interpret', 'JJ'),\n",
       " ('human', 'JJ'),\n",
       " ('language', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "tokens = nltk.word_tokenize(text)\n",
    "nltk.pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daef0130-a9af-4fa5-b175-95b6358b3104",
   "metadata": {},
   "source": [
    "# Named Entity Recognition (NER)\n",
    "- Identifies people, places, organizations, etc.\n",
    "- **When to use:** Information extraction, knowledge graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15a51c37-2f9c-4f9f-8525-74fe8404f617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It will form a Tree\n",
    "# from nltk import ne_chunk\n",
    "# tokens = nltk.word_tokenize(\"The US president stays in the White House.\")\n",
    "# tags = nltk.pos_tag(tokens)\n",
    "# ne_chunk(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64cad311-3cdb-47c6-9429-52ddf4d00fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('US', 'GSP'), ('White House', 'FACILITY')]\n"
     ]
    }
   ],
   "source": [
    "from nltk import ne_chunk\n",
    "from nltk.tree import Tree\n",
    "\n",
    "tokens = nltk.word_tokenize(\"The US president stays in the White House.\")\n",
    "tags = nltk.pos_tag(tokens)\n",
    "tree = ne_chunk(tags)\n",
    "\n",
    "# Extract entities as (text, label)\n",
    "entities = []\n",
    "for subtree in tree:\n",
    "    if isinstance(subtree, Tree):\n",
    "        entity_text = \" \".join(token for token, pos in subtree.leaves())\n",
    "        entities.append((entity_text, subtree.label()))\n",
    "\n",
    "print(entities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a8152e-9a5f-41f8-b240-a67f9c6756e5",
   "metadata": {},
   "source": [
    "**Closing Notes**\n",
    "\n",
    "- Tokenization: First step for all NLP tasks.\n",
    "- Whitespace vs WordPunct: Choose based on punctuation importance.\n",
    "- N-grams: Add context but require more data for larger N.\n",
    "- Stemming vs Lemmatization: Speed vs accuracy trade-off.\n",
    "- Stopwords: Remove for efficiency unless meaningful in context.\n",
    "- POS & NER: Provide structural and entity-level understanding of text."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
