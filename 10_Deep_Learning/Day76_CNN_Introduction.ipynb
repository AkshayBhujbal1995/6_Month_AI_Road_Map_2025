{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1744afc6-1246-44de-9802-79d85d9b6675",
   "metadata": {},
   "source": [
    "# Introduction to Convolutional Neural Networks - CNN\n",
    "\n",
    "Welcome back to my Deep Learning documentation!  \n",
    "\n",
    "In this notebook, we begin our journey into **Convolutional Neural Networks (CNNs)**, one of the most powerful models in deep learning for **images, videos, and computer vision tasks**.  \n",
    "\n",
    "\n",
    "#  What is CNN?\n",
    "\n",
    "- CNN = **Convolution Layer + Neural Network**  \n",
    "- Unlike traditional ANNs, CNNs are designed to handle **spatial data** (images/videos).  \n",
    "\n",
    "**Example:**\n",
    "    \n",
    "- A CNN can look at a ðŸ˜€ emoji and classify it as **Happy**.  \n",
    "- A CNN can look at a ðŸ˜¢ emoji and classify it as **Sad**.  \n",
    "\n",
    "**Key idea:** CNNs automatically detect patterns like edges, shapes, and colors in images, which then combine to recognize complex objects.\n",
    "\n",
    "\n",
    "#  Data for CNNs\n",
    "\n",
    "##  Image Representation\n",
    "\n",
    "- Every image is made of **pixels**.  \n",
    "- Each pixel has an intensity value between **0 and 255**.  \n",
    "  - 0 â†’ black / no intensity.  \n",
    "  - 255 â†’ maximum brightness of a color.  \n",
    "\n",
    "**Example:**\n",
    "      \n",
    "- A pure black pixel = 0.  \n",
    "- A pure white pixel = 255.  \n",
    "- A gray pixel = somewhere between (e.g., 128).  \n",
    "\n",
    "## Channels in Images\n",
    "\n",
    "- **Grayscale (2D)**: Black & White images, only one channel.  \n",
    "- **RGB (3D)**: Color images, 3 channels (Red, Green, Blue).  \n",
    "\n",
    "**Example:**\n",
    "\n",
    "- A grayscale photo of a handwritten digit (MNIST dataset).  \n",
    "- A color image of a cat/dog has 3 channels (R, G, B).  \n",
    "\n",
    "\n",
    "#  Prerequisites for CNN\n",
    "\n",
    "Before learning CNNs, two areas are important:  \n",
    "\n",
    "## Image Processing\n",
    "\n",
    "- Deals with **enhancing or transforming images**.  \n",
    "- Tasks: resizing, filtering, edge detection, noise removal.  \n",
    "\n",
    "**Example:** Instagram filters = Image Processing.  \n",
    "\n",
    "## Computer Vision\n",
    "\n",
    "- Deals with making computers **understand the content of images**.  \n",
    "- Tasks: object detection, face recognition, image classification.  \n",
    "\n",
    "**Example:** Facebook automatically tagging people in photos = Computer Vision.  \n",
    "\n",
    "\n",
    "#  Architecture of CNN\n",
    "\n",
    "A standard CNN has **4 key layers**:  \n",
    "\n",
    "1. Convolution  \n",
    "2. Max Pooling  \n",
    "3. Flatten  \n",
    "4. Fully Connected (ANN)  \n",
    "\n",
    "Each plays a specific role in extracting features and making predictions.  \n",
    "\n",
    "\n",
    "#  Convolution Layer\n",
    "\n",
    "##  What is Convolution?\n",
    "\n",
    "- Convolution = **mathematical operation** that combines two pieces of information:  \n",
    "  1. **Input Image** (matrix of pixels).  \n",
    "  2. **Filter / Kernel (Feature Detector)** â†’ a small matrix like 3Ã—3 or 5Ã—5.  \n",
    "\n",
    "Output = **Feature Map** (convolved image).  \n",
    "\n",
    "\n",
    "\n",
    "##  Real-Life Analogy\n",
    "Imagine looking at a photo through a **magnifying glass with a pattern**.  \n",
    "\n",
    "- If the pattern is horizontal lines â†’ the glass highlights horizontal edges.  \n",
    "- If the pattern is vertical lines â†’ the glass highlights vertical edges.  \n",
    "\n",
    "Thatâ€™s how convolution detects features like edges, curves, and textures.  \n",
    "\n",
    "\n",
    "##  Striding\n",
    "\n",
    "- Stride = how many steps the filter moves across the image.  \n",
    "- Stride = 1 â†’ moves one pixel at a time (more detail, larger output).  \n",
    "- Stride = 2 â†’ skips more pixels (smaller output, faster computation).  \n",
    "\n",
    "\n",
    "##  Padding\n",
    "\n",
    "- Problem: Each convolution reduces image size.  \n",
    "- Solution: **Padding** adds an extra border of 0s around the image.  \n",
    "- Helps preserve edge information.  \n",
    "\n",
    "**Example:**\n",
    "    \n",
    "- Input 6Ã—6 image â†’ Convolution â†’ 4Ã—4 output.  \n",
    "- With padding â†’ size maintained (e.g., 6Ã—6 stays 6Ã—6).  \n",
    "\n",
    "\n",
    "#  Max Pooling Layer\n",
    "\n",
    "##  What is Pooling?\n",
    "\n",
    "- Pooling = reduces the size of the feature map.  \n",
    "- Default = **2Ã—2 Max Pooling** â†’ picks the maximum value from each 2Ã—2 block.  \n",
    "\n",
    "\n",
    "##  Why Pooling?\n",
    "\n",
    "1. Reduces computational load.  \n",
    "2. Keeps the most important features.  \n",
    "3. Makes the model more robust (ignores minor variations).  \n",
    "\n",
    "\n",
    "\n",
    "##  Example\n",
    "\n",
    "Feature map section:  \n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1 & 3 \\\\\n",
    "2 & 4\n",
    "\\end{bmatrix}\n",
    "$$  \n",
    "After 2Ã—2 max pooling â†’ **4** (the maximum).  \n",
    "\n",
    " Think of it like **taking the strongest signal** and discarding the weaker ones.  \n",
    "\n",
    "\n",
    "#  Flatten Layer\n",
    "\n",
    "- Takes the pooled feature maps (2D) and converts them into a **1D vector**.  \n",
    "- This long vector acts as the **input to the fully connected ANN layer**.  \n",
    "\n",
    "**Example:**\n",
    "\n",
    "- Pooled maps: 5Ã—5 â†’ Flatten â†’ 25 values in a single row.  \n",
    "\n",
    "\n",
    "#  Fully Connected Layer (ANN)\n",
    "\n",
    "- Works just like a regular **Artificial Neural Network**.  \n",
    "- The flattened vector is input.  \n",
    "- Outputs predictions (e.g., cat, dog, happy, sad).  \n",
    "\n",
    "**Example:**\n",
    "    \n",
    "- Input photo â†’ CNN layers extract features â†’ ANN outputs:  \n",
    "  - Cat = 0.85 probability  \n",
    "  - Dog = 0.10  \n",
    "  - Other = 0.05  \n",
    "\n",
    "Prediction = **Cat**   \n",
    "\n",
    "\n",
    "#  ANN vs CNN (Key Difference)\n",
    "\n",
    "- In **ANN**:  \n",
    "  - Training adjusts **weights** of connections.  \n",
    "\n",
    "- In **CNN**:  \n",
    "  - Training adjusts **filter values (kernels)**.  \n",
    "\n",
    "This is why CNNs are much better at handling images â€” they learn **filters** that detect edges, colors, and shapes automatically.  \n",
    "\n",
    "\n",
    "# Summary\n",
    "\n",
    "- CNNs are specialized for **images & videos**.  \n",
    "- They use pixels (0â€“255 values) as input.  \n",
    "- Main layers:  \n",
    "  1. Convolution â†’ feature extraction  \n",
    "  2. Max Pooling â†’ dimensionality reduction  \n",
    "  3. Flatten â†’ converts into 1D vector  \n",
    "  4. Fully Connected Layer â†’ prediction  \n",
    "\n",
    "- **ANN updates weights**; **CNN updates filters**.  \n",
    "\n",
    "\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "In this notebook, we:  \n",
    "- Learned why CNNs are important for images and videos.  \n",
    "- Understood image basics (pixels, grayscale vs RGB).  \n",
    "- Covered CNN layers: Convolution, Pooling, Flatten, Fully Connected.  \n",
    "- Compared ANN and CNN training.  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
