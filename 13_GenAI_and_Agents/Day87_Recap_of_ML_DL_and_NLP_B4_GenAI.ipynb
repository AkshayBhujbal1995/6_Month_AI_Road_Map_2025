{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e185c8a1-92f0-49da-8f8b-e03545cac0ba",
   "metadata": {},
   "source": [
    "# **AI Learning Journey**\n",
    "\n",
    "From today, I am starting my exploration into **Generative AI (GenAI)** and **Agentic AI**.  \n",
    "But before we dive into these exciting areas, it’s important to strengthen the foundation.  \n",
    "\n",
    "That’s why I am first recapping some **essential theoretical concepts** from:  \n",
    "- **Machine Learning (ML)**  \n",
    "- **Deep Learning (DL)**  \n",
    "- **Natural Language Processing (NLP)**  \n",
    "\n",
    "This recap will help :  \n",
    "\n",
    "- Revisit the key fundamentals I have already learned.  \n",
    "- Connect these concepts to the bigger picture of GenAI and Agentic AI.  \n",
    "- Build a strong base to understand advanced applications.  \n",
    "\n",
    "\n",
    "> Let’s get started with the recap!\n",
    "\n",
    "#  List of Concepts to Recap  \n",
    "\n",
    "## Machine Learning  \n",
    "1. What is Machine Learning?  \n",
    "2. Types of Machine Learning  \n",
    "   - Supervised Learning  \n",
    "   - Unsupervised Learning  \n",
    "   - Reinforcement Learning  \n",
    "3. Key ML Concepts  \n",
    "   - Training vs Test Data  \n",
    "   - Overfitting & Underfitting  \n",
    "   - Bias-Variance Tradeoff  \n",
    "   - Evaluation Metrics  \n",
    "\n",
    "## Deep Learning  \n",
    "1. What is Deep Learning?  \n",
    "2. Neural Network Basics  \n",
    "   - Neuron (Perceptron)  \n",
    "   - Activation Functions  \n",
    "   - Forward & Backward Propagation  \n",
    "3. Types of Neural Networks  \n",
    "   - Feedforward Neural Network (FNN)  \n",
    "   - Convolutional Neural Network (CNN)  \n",
    "   - Recurrent Neural Network (RNN)  \n",
    "   - Transformers  \n",
    "4. Key DL Concepts  \n",
    "   - Epochs, Batches, Iterations  \n",
    "   - Learning Rate  \n",
    "   - Regularization  \n",
    "   - Loss Functions  \n",
    "\n",
    "## Natural Language Processing (NLP)  \n",
    "1. What is NLP?  \n",
    "2. Core NLP Tasks  \n",
    "3. Traditional NLP vs DL-based NLP  \n",
    "4. Modern NLP with Transformers  \n",
    "\n",
    "## Comparison  \n",
    "- Machine Learning vs Deep Learning  \n",
    "\n",
    "## Why This Matters for AI & Agents  \n",
    "\n",
    "#  Machine Learning Recap  \n",
    "\n",
    "## What is Machine Learning?  \n",
    "Machine Learning (ML) is the science of making computers **learn from data** without being explicitly programmed.  \n",
    "Instead of writing rules, we feed data and let the computer **discover patterns** to make predictions or decisions.  \n",
    "\n",
    "> Example: Predicting house prices based on location, size, and number of rooms.  \n",
    "\n",
    "\n",
    "## Types of Machine Learning  \n",
    "\n",
    "**1. Supervised Learning**  \n",
    "- Learn from **labeled data** (input + correct output given).  \n",
    "- Goal: predict outcomes for new inputs.  \n",
    "- Examples:  \n",
    "  - Predicting exam scores from study hours.  \n",
    "  - Spam detection in emails.  \n",
    "- Algorithms: Linear Regression, Logistic Regression, Decision Trees, Random Forests, SVM, Neural Networks.  \n",
    "\n",
    "**2. Unsupervised Learning**  \n",
    "- Learn from **unlabeled data** (no correct output).  \n",
    "- Goal: find hidden patterns or groups.  \n",
    "- Examples:  \n",
    "  - Customer segmentation for marketing.  \n",
    "  - Market basket analysis (products often bought together).  \n",
    "- Algorithms: K-Means, Hierarchical Clustering, PCA.  \n",
    "\n",
    "**3. Reinforcement Learning (RL)**  \n",
    "- Learn by **trial and error** with rewards or penalties.  \n",
    "- Agent interacts with environment → improves decisions over time.  \n",
    "- Examples:  \n",
    "  - Self-driving cars.  \n",
    "  - AlphaGo beating human champions.  \n",
    "\n",
    "## Key ML Concepts  \n",
    "\n",
    "### Training vs Test Data  \n",
    "- **Training Data** → used to teach the model.  \n",
    "- **Test Data** → used to check how well the model generalizes.  \n",
    "\n",
    "### Overfitting & Underfitting  \n",
    "- **Overfitting** → model memorizes training data (bad for new data).  \n",
    "- **Underfitting** → model too simple, fails to capture patterns.  \n",
    "\n",
    "### Bias-Variance Tradeoff  \n",
    "- **High Bias** → oversimplified, underfits.  \n",
    "- **High Variance** → too complex, overfits.  \n",
    "- Goal: balance bias & variance.  \n",
    "\n",
    "### Evaluation Metrics  \n",
    "- Regression → RMSE, MAE, R²  \n",
    "- Classification → Accuracy, Precision, Recall, F1-Score, AUC  \n",
    "\n",
    "\n",
    "\n",
    "#  Deep Learning Recap  \n",
    "\n",
    "## What is Deep Learning?  \n",
    "- Subset of ML using **Neural Networks** with multiple layers.  \n",
    "- Handles **complex data** like images, text, audio.  \n",
    "- Inspired by how the human brain processes information.  \n",
    "\n",
    "\n",
    "\n",
    "## Neural Network Basics  \n",
    "\n",
    "### Neuron (Perceptron)  \n",
    "- Fundamental unit of a neural network.  \n",
    "- Takes inputs → multiplies with weights → adds bias → applies activation → outputs result.  \n",
    "\n",
    "Formula:  \n",
    "\n",
    "$$\n",
    "y = f(Σ (wᵢ \\* xᵢ) + b)\n",
    "$$\n",
    "\n",
    "### Activation Functions  \n",
    "- Decide whether a neuron should activate.  \n",
    "- Common functions:  \n",
    "  - **Sigmoid** → outputs between 0–1 (good for probabilities).  \n",
    "  - **ReLU** → most widely used, avoids vanishing gradients.  \n",
    "  - **Softmax** → multi-class classification.  \n",
    "\n",
    "### Forward Propagation  \n",
    "- Data flows **input → hidden layers → output**.  \n",
    "\n",
    "### Backward Propagation (Backprop)  \n",
    "- Adjusts weights using **Gradient Descent** to reduce errors.  \n",
    "\n",
    "\n",
    "\n",
    "## Types of Neural Networks  \n",
    "\n",
    "### Feedforward Neural Network (FNN)  \n",
    "- Simplest form, data flows forward only.  \n",
    "\n",
    "### Convolutional Neural Network (CNN)  \n",
    "- Specially designed for **images and spatial data**.  \n",
    "\n",
    "### Recurrent Neural Network (RNN)  \n",
    "- Best for **sequential data** (time series, speech, text).  \n",
    "\n",
    "### Transformers  \n",
    "- Advanced architecture for **NLP & AI Agents**.  \n",
    "- Powers modern LLMs like GPT, BERT.  \n",
    "\n",
    "\n",
    "\n",
    "## Key DL Concepts  \n",
    "\n",
    "### Epochs, Batches, Iterations  \n",
    "- **Epoch** → one full pass through training data.  \n",
    "- **Batch** → subset of training data used in one iteration.  \n",
    "- **Iteration** → one update step using a batch.  \n",
    "\n",
    "### Learning Rate  \n",
    "- Controls step size in optimization.  \n",
    "- Too high → unstable.  \n",
    "- Too low → very slow learning.  \n",
    "\n",
    "### Regularization  \n",
    "- Prevents overfitting.  \n",
    "- Techniques: Dropout, L2 Regularization, Batch Normalization.  \n",
    "\n",
    "### Loss Functions  \n",
    "- Measure how wrong predictions are.  \n",
    "- Regression → MSE, MAE  \n",
    "- Classification → Cross-Entropy  \n",
    "\n",
    "\n",
    "\n",
    "#  Natural Language Processing (NLP)  \n",
    "\n",
    "## What is NLP?  \n",
    "NLP (Natural Language Processing) is the branch of AI that focuses on enabling computers to **understand, interpret, and generate human language**.  \n",
    "It is the core of chatbots, translation apps, voice assistants, and modern **GenAI systems**.  \n",
    "\n",
    "\n",
    "\n",
    "## Core NLP Tasks  \n",
    "\n",
    "- **Text Preprocessing** → Tokenization, Stopword Removal, Stemming, Lemmatization  \n",
    "- **Sentiment Analysis** → Understanding emotions in text (positive/negative/neutral)  \n",
    "- **Named Entity Recognition (NER)** → Identifying entities like names, dates, locations  \n",
    "- **Machine Translation** → Translating text between languages  \n",
    "- **Text Summarization** → Creating concise versions of long texts  \n",
    "- **Question Answering** → Answering queries from documents  \n",
    "- **Language Generation** → Generating human-like responses (LLMs)  \n",
    "\n",
    "\n",
    "\n",
    "## Traditional NLP vs DL-based NLP  \n",
    "\n",
    "- **Traditional NLP**  \n",
    "  - Relied on rules and statistical models (Bag-of-Words, TF-IDF, n-grams).  \n",
    "  - Worked on small text tasks but struggled with context and meaning.  \n",
    "\n",
    "- **Deep Learning-based NLP**  \n",
    "  - Uses embeddings (Word2Vec, GloVe, FastText).  \n",
    "  - Captures semantic meaning of words.  \n",
    "  - Can handle context better.  \n",
    "\n",
    "\n",
    "## Modern NLP with Transformers  \n",
    "\n",
    "- Transformers introduced **Attention Mechanism**, which allows models to focus on important words in context.  \n",
    "- Examples: BERT, GPT, T5.  \n",
    "- Powers today’s **chatbots, search engines, summarizers, AI Agents**.  \n",
    "\n",
    "\n",
    "\n",
    "#  Machine Learning vs Deep Learning  \n",
    "\n",
    "| Feature | Machine Learning | Deep Learning |\n",
    "|---------|------------------|---------------|\n",
    "| Data Requirement | Small/Medium datasets | Large datasets |\n",
    "| Feature Engineering | Manual | Learns automatically |\n",
    "| Algorithms | Regression, SVM, Trees | Neural Networks (CNN, RNN, Transformers) |\n",
    "| Training Time | Fast | Slow, needs GPU |\n",
    "| Interpretability | Easier | Harder (\"black box\") |\n",
    "\n",
    "\n",
    "#  Why This Matters for AI & Agents  \n",
    "\n",
    "- **AI Agents** need **decision-making** ability (ML) + **complex data understanding** (DL) + **language interaction (NLP)**.  \n",
    "- Examples:  \n",
    "  - A stock-trading agent → uses **ML regression/classification**.  \n",
    "  - A vision-based agent (robot) → uses **DL (CNNs)** for image understanding.  \n",
    "  - A conversational agent → uses **NLP with Transformers** to understand and generate language.  \n",
    "\n",
    "> That’s why ML, DL, and NLP fundamentals are essential before diving into **GenAI** and **Agentic AI**.  \n",
    "\n",
    "\n",
    "\n",
    "#  Key Takeaways  \n",
    "\n",
    "- **Machine Learning** teaches systems to learn patterns from data.  \n",
    "- **Deep Learning** uses neural networks to capture complex, high-dimensional patterns.  \n",
    "- **NLP** enables computers to understand and generate human language.  \n",
    "- Together, ML + DL + NLP provide the foundation for building **powerful AI Agents**.  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
