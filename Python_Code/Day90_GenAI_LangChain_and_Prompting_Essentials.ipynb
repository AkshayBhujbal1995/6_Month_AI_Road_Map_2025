{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ebd32c1-3982-46bb-aabe-373530207835",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; font-size:28px; font-weight:bold;\">\n",
    "GenAI: LangChain and Prompting Essentials\n",
    "</div>\n",
    "\n",
    "\n",
    "This notebook covers **LangChain fundamentals** and **prompting techniques**, along with practical steps to build an **LLM-powered financial data extraction app**.  \n",
    "We will go step by step, starting from **prompting basics** to **LangChain setup and usage**.\n",
    "\n",
    "\n",
    "> ** Note:**  \n",
    "> I would personally use **VS Code** or **Google Colab** for running these notebooks.  \n",
    "> \n",
    "> - In **VS Code**, I create a `.env` file to store my API keys and load them in the `.py` script. This ensures I can **publicly share the code without exposing API keys**.  \n",
    "> - For documentation purposes here, I am using a **Jupyter Notebook** in **Markdown only** and haven’t run any cells.  \n",
    "> - If you want to try this in **Google Colab**, make sure to **set the runtime to GPU** for faster performance.  \n",
    "> - **Never share your API keys publicly**!\n",
    "\n",
    "\n",
    "**Table of Contents (Flow)**\n",
    "\n",
    "1. Elements of a Good Prompt  \n",
    "2. Zero-shot, One-shot, and Few-shot Prompting  \n",
    "3. LangChain Installation  \n",
    "4. Groq and Ollama Setup  \n",
    "   - Groq  \n",
    "   - Ollama  \n",
    "5. Calling an LLM from LangChain  \n",
    "6. Prompt Templates & Chains  \n",
    "7. Output Parsers  \n",
    "8. Build a Financial Data Extraction App (Step by Step)  \n",
    "   - Step 1: Import libraries  \n",
    "   - Step 2: Define schema  \n",
    "   - Step 3: Create prompt  \n",
    "   - Step 4: Create LLM chain  \n",
    "   - Step 5: Run with sample input  \n",
    "9. Summary  \n",
    "\n",
    "    \n",
    "#  Elements of a Good Prompt\n",
    "\n",
    "A **prompt** is the input we give to a Large Language Model (LLM).  \n",
    "A good prompt ensures the model understands *context*, *task*, and *format*.\n",
    "\n",
    "**Key elements:**\n",
    "    \n",
    "- **Role/Context**: Tell the model *who it is* or *what role it should assume*.\n",
    "- **Task Instruction**: Be explicit about what you want.\n",
    "- **Constraints**: Add rules such as word limits, tone, or style.\n",
    "- **Examples** (if needed): Demonstrate the expected output.\n",
    "- **Output Format**: JSON, table, bullet points, etc.\n",
    "\n",
    "**Example Prompt:**\n",
    "``` bash\n",
    "\n",
    "You are a financial analyst.\n",
    "Summarize the following earnings call transcript into 3 bullet points.\n",
    "Focus only on revenue, profit, and future outlook.\n",
    "Return the result in JSON with keys: \"revenue\", \"profit\", \"outlook\".\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "#  Zero-shot, One-shot, and Few-shot Prompting\n",
    "\n",
    "## **Zero-shot Prompting**  \n",
    "\n",
    "- No examples given, just instructions.  \n",
    "- Example:  \n",
    "``` bash\n",
    "\n",
    "Translate \"How are you?\" into French.\n",
    "\n",
    "```\n",
    "\n",
    "## **One-shot Prompting**  \n",
    "- One example provided to guide the model.  \n",
    "- Example:  \n",
    "``` bash\n",
    "\n",
    "Translate English to French.\n",
    "\n",
    "English: Good morning\n",
    "French: Bonjour\n",
    "\n",
    "English: How are you?\n",
    "French:\n",
    "\n",
    "```\n",
    "\n",
    "## **Few-shot Prompting**  \n",
    "- Multiple examples given, helps improve accuracy.  \n",
    "- Example:  \n",
    "``` bash\n",
    "\n",
    "Translate English to French.\n",
    "\n",
    "English: Good morning\n",
    "French: Bonjour\n",
    "\n",
    "English: I love you\n",
    "French: Je t'aime\n",
    "\n",
    "English: How are you?\n",
    "French:\n",
    "\n",
    "````\n",
    "\n",
    "\n",
    "#  LangChain Installation\n",
    "\n",
    "To install LangChain and dependencies:\n",
    "\n",
    "```bash\n",
    "pip install langchain langchain-community langchain-core\n",
    "pip install openai groq ollama\n",
    "````\n",
    "\n",
    "If you plan to use Jupyter:\n",
    "\n",
    "```bash\n",
    "pip install ipykernel\n",
    "```\n",
    "\n",
    "\n",
    "#  Groq and Ollama Setup\n",
    "\n",
    "## Groq\n",
    "\n",
    "* Groq provides **fast inference for LLMs**.\n",
    "* Sign up at [Groq](https://groq.com/), get an API key.\n",
    "* Set your API key in the environment:\n",
    "\n",
    "```bash\n",
    "export GROQ_API_KEY=\"your_api_key_here\" # never share \n",
    "```\n",
    "\n",
    "## Ollama\n",
    "\n",
    "* Ollama runs **open-source models locally** (like LLaMA, Mistral, etc.).\n",
    "* Installation (Linux/Mac):\n",
    "\n",
    "```bash\n",
    "curl -fsSL https://ollama.com/install.sh | sh\n",
    "```\n",
    "\n",
    "* Run a model:\n",
    "\n",
    "```bash\n",
    "ollama run mistral\n",
    "```\n",
    "\n",
    "\n",
    "#  Calling an LLM from LangChain\n",
    "\n",
    "LangChain provides wrappers to interact with LLMs.\n",
    "\n",
    "```python\n",
    "from langchain.llms import Ollama\n",
    "\n",
    "# Initialize model\n",
    "llm = Ollama(model=\"mistral\")\n",
    "\n",
    "# Run query\n",
    "response = llm(\"Write a short poem about finance.\")\n",
    "print(response)\n",
    "```\n",
    "\n",
    "\n",
    "#  Prompt Templates & Chains\n",
    "\n",
    "**Prompt Templates** allow you to create reusable prompts with variables.\n",
    "\n",
    "```python\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"You are a financial assistant.\n",
    "Extract the following information from the text:\n",
    "Company: {company}\n",
    "Text: {text}\n",
    "Return JSON with keys: revenue, profit, outlook.\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"company\", \"text\"])\n",
    "\n",
    "final_prompt = prompt.format(company=\"Tesla\", text=\"Tesla reported revenue of $25B and profit of $2B...\")\n",
    "print(final_prompt)\n",
    "```\n",
    "\n",
    "**Chains**\n",
    "Chains connect **prompt → LLM → parser → output** into a pipeline.\n",
    "\n",
    "\n",
    "\n",
    "#  Output Parsers\n",
    "\n",
    "Output parsers enforce structured results.\n",
    "\n",
    "```python\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "\n",
    "schemas = [\n",
    "    ResponseSchema(name=\"revenue\", description=\"Revenue details\"),\n",
    "    ResponseSchema(name=\"profit\", description=\"Profit details\"),\n",
    "    ResponseSchema(name=\"outlook\", description=\"Future outlook\"),\n",
    "]\n",
    "\n",
    "parser = StructuredOutputParser.from_response_schemas(schemas)\n",
    "format_instructions = parser.get_format_instructions()\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Extract financial data.\n",
    "\n",
    "Text: Tesla reported revenue of $25B and profit of $2B. Outlook is positive.\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "print(prompt)\n",
    "```\n",
    "\n",
    "\n",
    "#  Build a Financial Data Extraction App (Step by Step)\n",
    "\n",
    "We will build a simple **financial data extractor** using LangChain.\n",
    "\n",
    "**Step 1: Import libraries**\n",
    "\n",
    "```python\n",
    "from langchain.llms import Ollama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "```\n",
    "\n",
    "**Step 2: Define schema**\n",
    "\n",
    "```python\n",
    "schemas = [\n",
    "    ResponseSchema(name=\"revenue\", description=\"Revenue details\"),\n",
    "    ResponseSchema(name=\"profit\", description=\"Profit details\"),\n",
    "    ResponseSchema(name=\"outlook\", description=\"Future outlook\"),\n",
    "]\n",
    "\n",
    "parser = StructuredOutputParser.from_response_schemas(schemas)\n",
    "format_instructions = parser.get_format_instructions()\n",
    "```\n",
    "\n",
    "**Step 3: Create prompt**\n",
    "\n",
    "```python\n",
    "template = \"\"\"You are a financial analyst.\n",
    "Extract revenue, profit, and outlook from the following text.\n",
    "\n",
    "Text: {text}\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"text\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions},\n",
    ")\n",
    "```\n",
    "\n",
    "**Step 4: Create LLM chain**\n",
    "\n",
    "```python\n",
    "llm = Ollama(model=\"mistral\")\n",
    "chain = LLMChain(llm=llm, prompt=prompt)\n",
    "```\n",
    "\n",
    "**Step 5: Run with sample input**\n",
    "\n",
    "```python\n",
    "text = \"Apple reported revenue of $90B and profit of $25B. The outlook is strong with growth in services.\"\n",
    "result = chain.run(text=text)\n",
    "parsed = parser.parse(result)\n",
    "\n",
    "print(parsed)\n",
    "```\n",
    "\n",
    "**Expected Output:**\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"revenue\": \"$90B\",\n",
    "  \"profit\": \"$25B\",\n",
    "  \"outlook\": \"strong with growth in services\"\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "#  Summary\n",
    "\n",
    "* Learned **prompting techniques** (zero, one, few-shot).\n",
    "* Installed **LangChain, Groq, Ollama**.\n",
    "* Used **Prompt Templates & Chains**.\n",
    "* Added **Output Parsers** for structured data.\n",
    "* Built a **Financial Data Extraction App** using LangChain.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
