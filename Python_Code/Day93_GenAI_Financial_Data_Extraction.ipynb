{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bb4017f-3043-4104-936b-611dc662933e",
   "metadata": {},
   "source": [
    "**GenAI: Financial Data Extraction**\n",
    "\n",
    "Turn the theory from Day 90 into practice: **build a working financial data extractor** using LangChain, Prompt Templates, Chains, and Structured Output Parsers.\n",
    "\n",
    "**Goal:** Extract revenue, profit, and outlook from financial texts using LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c6f0bd-3aad-46f5-9e24-6afc38c4f50b",
   "metadata": {},
   "source": [
    "# Notebook Setup Reminder\n",
    "\n",
    "* We will **reuse Ollama or Groq LLM** already initialized in Day 92.\n",
    "* Ensure required libraries are installed (`langchain`, `ollama`, `langchain_ollama`, `langchain_groq`).\n",
    "* The code will follow a **step-by-step pipeline**: import → define schema → create prompt → create chain → run sample input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c28a9f-e57f-4ea3-a76a-42a1d5b46440",
   "metadata": {},
   "source": [
    "# Import Libraries\n",
    "\n",
    "- ```Ollama``` → Local LLM\n",
    "- ```PromptTemplate``` → Reusable prompts\n",
    "- ```LLMChain → Connect prompt``` → LLM → output\n",
    "- ```StructuredOutputParser``` → Ensures structured output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "115852bd-8170-49f3-9fec-54c3e7e8e6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import Ollama\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069691ca-9b45-45e6-8b43-fa2c247b03fd",
   "metadata": {},
   "source": [
    "# Define Schema\n",
    "\n",
    "- Each schema defines a **key** and **description**.\n",
    "- Parser will **validate and structure LLM output** as JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2f06f98-524e-4dd8-a86f-531af240e767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the structure of the extracted data\n",
    "schemas = [\n",
    "    ResponseSchema(name=\"revenue\", description=\"Revenue details\"),\n",
    "    ResponseSchema(name=\"profit\", description=\"Profit details\"),\n",
    "    ResponseSchema(name=\"outlook\", description=\"Future outlook\"),\n",
    "]\n",
    "\n",
    "# Initialize parser\n",
    "parser = StructuredOutputParser.from_response_schemas(schemas)\n",
    "\n",
    "# Get formatting instructions for LLM prompt\n",
    "format_instructions = parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892a6e27-fa7f-47d4-b336-b56aa64e2edc",
   "metadata": {},
   "source": [
    "# Create Prompt\n",
    "- **text** → Variable to input financial data.\n",
    "- **format_instructions** → Ensures LLM outputs in structured JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2df759a4-2ffd-40f1-83d8-c339ed53801e",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are a financial analyst.\n",
    "Extract revenue, profit, and outlook from the following text.\n",
    "Text: {text}\n",
    "\n",
    "Return the output **strictly as JSON** with all keys: \n",
    "\"revenue\", \"profit\", \"outlook\".\n",
    "- Do NOT add any explanations, bullet points, or markdown.\n",
    "- If any value is missing, put \"N/A\".\n",
    "\n",
    "Example output:\n",
    "{{\n",
    "  \"revenue\": \"value\",\n",
    "  \"profit\": \"value\",\n",
    "  \"outlook\": \"value\"\n",
    "}}\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"text\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc93ef6c-18e1-41c2-a0b1-9ca5fe941382",
   "metadata": {},
   "source": [
    "# Create LLM Chain\n",
    "LLMChain links **prompt → LLM → structured output.**\n",
    "\n",
    "We can switch ```llm_local``` or ```llm_groq``` depending on whether we want local or cloud execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fde217da-8dfd-413a-b65c-1f7e0fa222be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "# Local LLM setup\n",
    "llm_local = ChatOllama(\n",
    "    model=\"llama3.2:1b\",   # Model downloaded in Ollama\n",
    "    temperature=1.8,        # Creativity\n",
    "    num_predict=50         # Number of tokens generated\n",
    ")\n",
    "\n",
    "# Create chain using RunnableSequence style\n",
    "chain = prompt | llm_local  # no LLMChain needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a34a34-f21b-48c3-8549-2914126d9cd0",
   "metadata": {},
   "source": [
    "# Run with Sample Input\n",
    "\n",
    "- ```chain.run()``` → Sends text to LLM\n",
    "- ```parser.parse()``` → Converts LLM output into structured JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d70c97f4-f6e2-44cf-ad47-7bdc4913d027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'revenue': '$90B', 'profit': '$25B', 'outlook': 'Strong'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "text = \"Apple reported revenue of $90B and profit of $25B. The outlook is strong with growth in services.\"\n",
    "# Run chain\n",
    "result = chain.invoke({'text': text})\n",
    "\n",
    "# Get string content from AIMessage\n",
    "llm_output = result.content\n",
    "\n",
    "# Parse output\n",
    "parsed = parser.parse(llm_output)\n",
    "print(parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40464d1b-18f8-410d-b7a1-1a1071d483bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revenue: $90B\n",
      "Profit: $25B\n",
      "Outlook: Strong\n"
     ]
    }
   ],
   "source": [
    "print(\"Revenue:\", parsed['revenue'])\n",
    "print(\"Profit:\", parsed['profit'])\n",
    "print(\"Outlook:\", parsed['outlook'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "707b0907-b898-4774-85d8-446c525ee47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'revenue': '$45.7B', 'profit': '$7.2B', 'outlook': 'optimistic'}\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Tesla Inc. announced its Q2 2025 earnings, reporting total revenue of $45.7B, an increase of 20% \n",
    "compared to the previous quarter. Net profit rose to $7.2B, reflecting strong vehicle deliveries \n",
    "and growing energy product sales. The company highlighted robust growth in its solar and battery \n",
    "business segments. Outlook for Q3 2025 remains optimistic, with plans to expand production \n",
    "capacity and launch new vehicle models globally. CEO Elon Musk emphasized focus on sustainable \n",
    "energy solutions and innovation across all divisions.\n",
    "\"\"\"\n",
    "\n",
    "# Run chain\n",
    "result = chain.invoke({'text': text})\n",
    "\n",
    "# Get string content from AIMessage\n",
    "llm_output = result.content\n",
    "\n",
    "# Parse output\n",
    "parsed = parser.parse(llm_output)\n",
    "print(parsed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a3eeb46-d4bc-4e9f-96ba-6e94c1be2cd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revenue: $45.7B\n",
      "Profit: $7.2B\n",
      "Outlook: optimistic\n"
     ]
    }
   ],
   "source": [
    "print(\"Revenue:\", parsed['revenue'])\n",
    "print(\"Profit:\", parsed['profit'])\n",
    "print(\"Outlook:\", parsed['outlook'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb074983-a4b0-43e8-a6cd-50841dcf50bf",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "- Built a **Financial Data Extraction App** using LangChain.  \n",
    "- Used **Prompt Templates**, **Runnable Chains**, and **Structured Output Parsers**.  \n",
    "- Successfully extracted **revenue, profit, and outlook** from sample text.  \n",
    "# Next Steps\n",
    "\n",
    "- Try **Groq API** for faster cloud inference.  \n",
    "- Build a **Streamlit/Gradio interface** for user input.  \n",
    "- Handle **multiple companies** or **long reports**.  \n",
    "- Save extracted data to **CSV/Excel**.  \n",
    "\n",
    "# Practice Ideas\n",
    "\n",
    "- Extract additional fields like **CEO or expenses**.  \n",
    "- Compare results between **local LLM (Ollama)** and **cloud LLM (Groq)**.  \n",
    "- Make a mini **Financial Insights Bot** for Q&A using the same parser.  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
